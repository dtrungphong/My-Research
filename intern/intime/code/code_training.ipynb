{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import zipfile\n",
    "import random\n",
    "import math\n",
    "import datetime #timeline\n",
    "import sys\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from PIL import Image\n",
    "from shutil import copyfile, rmtree\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Model, optimizers, applications, models\n",
    "from tensorflow.keras import regularizers, layers, losses, metrics\n",
    "from tensorflow.keras import backend as K\n",
    "from diagonalWeight import DiagonalWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd ='./work/predict'\n",
    "ww = './weight_cut_data'\n",
    "w1 = '1a'\n",
    "w2 = '2a'\n",
    "w3 = '3a'\n",
    "w4 = '4a'\n",
    "############ set up manual\n",
    "num_model = 4\n",
    "num_disease = 9\n",
    "Input_Shape=(int(299*1.25),int(299*1.25),3)\n",
    "Target_Size = Input_Shape[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pretrained_Model_1 = applications.inception_v3.InceptionV3(input_shape=Input_Shape, #note\n",
    "                                                     include_top=False, \n",
    "                                                     input_tensor=None, #note\n",
    "                                                     weights=None)\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(Pretrained_Model_1)\n",
    "model_1.add(layers.GlobalAveragePooling2D()) # note Flatten())\n",
    "model_1.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_1.add(layers.Dropout(0.5))\n",
    "model_1.add(layers.Dense(num_disease, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_1.load_weights(os.path.join(ww,w1,'intime_model_2020-03-28_20:10:01.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pretrained_Model_2 = applications.inception_v3.InceptionV3(input_shape=Input_Shape, #note\n",
    "                                                     include_top=False, \n",
    "                                                     input_tensor=None, #note\n",
    "                                                     weights=None)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(Pretrained_Model_2)\n",
    "model_2.add(layers.GlobalAveragePooling2D()) # note Flatten())\n",
    "model_2.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_2.add(layers.Dropout(0.5))\n",
    "model_2.add(layers.Dense(num_disease, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_2.load_weights(os.path.join(ww,w2,'intime_model_2020-03-30_09:33:12.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pretrained_Model_3 = applications.inception_v3.InceptionV3(input_shape=Input_Shape, #note\n",
    "                                                     include_top=False, \n",
    "                                                     input_tensor=None, #note\n",
    "                                                     weights=None)\n",
    "model_3 = models.Sequential()\n",
    "model_3.add(Pretrained_Model_3)\n",
    "model_3.add(layers.GlobalAveragePooling2D()) # note Flatten())\n",
    "model_3.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_3.add(layers.Dropout(0.5))\n",
    "model_3.add(layers.Dense(num_disease, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_3.load_weights(os.path.join(ww,w3,'Intime_mode_mix_b+o+cut_fold_3_checkpointv3_2-49-0.8568.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pretrained_Model_4 = applications.inception_v3.InceptionV3(input_shape=Input_Shape, #note\n",
    "                                                     include_top=False, \n",
    "                                                     input_tensor=None, #note\n",
    "                                                     weights=None)\n",
    "model_4 = models.Sequential()\n",
    "model_4.add(Pretrained_Model_4)\n",
    "model_4.add(layers.GlobalAveragePooling2D()) # note Flatten())\n",
    "model_4.add(layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_4.add(layers.Dropout(0.5))\n",
    "model_4.add(layers.Dense(num_disease, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_4.load_weights(os.path.join(ww,w4,'Intime_mode_mix_b+o+cut_fold_4_checkpointv3_2-48-0.8922.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_f2 = Model(inputs=model_1.input,outputs = model_1.output)\n",
    "model_2_f2 = Model(inputs=model_2.input,outputs = model_2.output)\n",
    "model_3_f2 = Model(inputs=model_3.input,outputs = model_3.output)\n",
    "model_4_f2 = Model(inputs=model_4.input,outputs = model_4.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_f2.get_layer('inception_v3_input')._name = 'inception_v3_input_1'\n",
    "model_2_f2.get_layer('inception_v3_input')._name = 'inception_v3_input_2'\n",
    "model_3_f2.get_layer('inception_v3_input')._name = 'inception_v3_input_3'\n",
    "model_4_f2.get_layer('inception_v3_input')._name = 'inception_v3_input_4'\n",
    "model_1_f2.get_layer('inception_v3')._name = 'inception_v3_1'\n",
    "model_2_f2.get_layer('inception_v3')._name = 'inception_v3_2'\n",
    "model_3_f2.get_layer('inception_v3')._name = 'inception_v3_3'\n",
    "model_4_f2.get_layer('inception_v3')._name = 'inception_v3_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_f2.summary()\n",
    "model_2_f2.summary()\n",
    "model_3_f2.summary()\n",
    "model_4_f2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = layers.Reshape((model_1_f2.output.shape[1],1))(model_1_f2.output)\n",
    "f2 = layers.Reshape((model_2_f2.output.shape[1],1))(model_2_f2.output)\n",
    "f3 = layers.Reshape((model_3_f2.output.shape[1],1))(model_3_f2.output)\n",
    "f4 = layers.Reshape((model_4_f2.output.shape[1],1))(model_4_f2.output)\n",
    "\n",
    "merge = layers.concatenate([f1,f2,f3,f4],axis =2,name = 'concat')\n",
    "\n",
    "f = layers.TimeDistributed(layers.Dense(num_model,use_bias=False\n",
    "                 ,kernel_constraint=DiagonalWeight()\n",
    "                ,kernel_initializer='identity'\n",
    "                 ,kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-16, l2=1e-16)\n",
    "                ),name = 'ensemble')(merge)\n",
    "f = layers.Lambda(lambda x:K.sum(x, axis=2),name = 'combine')(f)\n",
    "f = layers.Lambda(lambda x: x/K.sum(x),name = 'to_one')(f)\n",
    "m = Model(inputs=[model_1_f2.input,model_2_f2.input,model_3_f2.input,model_4_f2.input],outputs = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in m.layers:\n",
    "    layer.trainable=True\n",
    "for layer in m.layers:\n",
    "    if layer.name != 'ensemble':\n",
    "        layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(os.path.join('./logs','Intime_cut_img_checkpointv5-{epoch:02d}-{acc:.4f}.hdf5')\n",
    "                                   ,monitor='acc'\n",
    "                                   ,mode = 'max', save_best_only=True, verbose=1)\n",
    "callbacks = [model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr=0.01 #initial learning rate for Optimizer1, to be changed by lr_scheduler\n",
    "Decay=0.0 # learning rate decay, not weight decay\n",
    "Momentum=0.9\n",
    "# Optimizer = optimizers.SGD(lr=Lr, decay=Decay, momentum=Momentum, clipnorm=5.0)\n",
    "Optimizer = optimizers.Adam(1e-5)\n",
    "Loss1='categorical_crossentropy'\n",
    "Loss2='sparse_categorical_crossentropy'\n",
    "Metrics='acc'\n",
    "m.compile(optimizer=Optimizer, loss=Loss1, metrics=[Metrics])\n",
    "# m.compile(optimizer=Optimizer, loss=Loss2, metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "classes= []\n",
    "i = 0\n",
    "for d in os.listdir(wd):\n",
    "    print(d)\n",
    "    for img in os.listdir(os.path.join(wd,d)):\n",
    "        try:\n",
    "            im = cv2.imread(os.path.join(wd,d,img))\n",
    "            im = im/255.\n",
    "            im = cv2.resize(im,Target_Size)\n",
    "            im = im[:,:,[2,1,0]]\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        x.append(im)\n",
    "        y_ = np.zeros(num_disease)\n",
    "        y_[i]=1\n",
    "        y.append(y_)\n",
    "#         y.append([i])\n",
    "        classes.append(i)\n",
    "    i+=1\n",
    "x =np.array(x)\n",
    "y =np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x =[x,x,x,x],y=y,epochs=200,verbose=2,batch_size = 24,class_weight='auto',callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rescale=1./255\n",
    "Rotation_Range=45\n",
    "Width_Shift_Range=0.2\n",
    "Height_Shift_Range=0.2\n",
    "Shear_Range=0.2\n",
    "Zoom_Range=0.2\n",
    "Fill_Mode='constant'\n",
    "stage_gen=ImageDataGenerator(\n",
    "                            featurewise_center = True,# test\n",
    "                            vertical_flip = True,# test\n",
    "                            rotation_range=90, # test\n",
    "                            rescale=Rescale,\n",
    "#                             rotation_range=Rotation_Range,\n",
    "                            width_shift_range=Width_Shift_Range,\n",
    "                            height_shift_range=Height_Shift_Range,\n",
    "                            shear_range=Shear_Range,\n",
    "                            zoom_range=Zoom_Range,\n",
    "                            horizontal_flip=True,\n",
    "                            channel_shift_range=10,\n",
    "                            fill_mode=Fill_Mode,\n",
    "                            cval = 0\n",
    "                            )\n",
    "Class_Mode='categorical'\n",
    "stage_generators2=stage_gen.flow_from_directory(wd,\n",
    "                  interpolation='bicubic',\n",
    "                  batch_size =1,\n",
    "                  class_mode=Class_Mode,\n",
    "                  shuffle=False,\n",
    "                  target_size=Target_Size)\n",
    "Y_pred_3 = m.predict([x,x,x,x])\n",
    "y_pred_3 = np.argmax(Y_pred_3, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(stage_generators2.classes, y_pred_3))\n",
    "print('Classification Report')\n",
    "target_names = [cls for cls in stage_generators2.class_indices]\n",
    "print(classification_report(classes, y_pred_3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = []\n",
    "x_p = []\n",
    "\n",
    "for img in os.listdir(os.path.join('./work/predict','Balanitis')):\n",
    "    try:\n",
    "        im = cv2.imread(os.path.join(wd,'Balanitis',img))\n",
    "        im = cv2.resize(im,Target_Size)\n",
    "        im = im / 255\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    x_p.append(im)\n",
    "    y_ = np.zeros(9,dtype = int)\n",
    "    y_[0] =1\n",
    "    y_p.append(y_)\n",
    "\n",
    "y_p = np.array(y_p)\n",
    "x_p = np.array(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rescale=1./255\n",
    "Rotation_Range=45\n",
    "Width_Shift_Range=0.2\n",
    "Height_Shift_Range=0.2\n",
    "Shear_Range=0.2\n",
    "Zoom_Range=0.2\n",
    "Fill_Mode='constant'\n",
    "stage_gen=ImageDataGenerator(\n",
    "                            featurewise_center = True,# test\n",
    "                            vertical_flip = True,# test\n",
    "                            rotation_range=90, # test\n",
    "                            rescale=Rescale,\n",
    "#                             rotation_range=Rotation_Range,\n",
    "                            width_shift_range=Width_Shift_Range,\n",
    "                            height_shift_range=Height_Shift_Range,\n",
    "                            shear_range=Shear_Range,\n",
    "                            zoom_range=Zoom_Range,\n",
    "                            horizontal_flip=True,\n",
    "                            channel_shift_range=10,\n",
    "                            fill_mode=Fill_Mode,\n",
    "                            cval = 0\n",
    "                            )\n",
    "Class_Mode='categorical'\n",
    "stage_generators2=stage_gen.flow_from_directory(wd,\n",
    "                  interpolation='bicubic',\n",
    "                  batch_size =1,\n",
    "                  class_mode=Class_Mode,\n",
    "                  shuffle=False,\n",
    "                  target_size=Target_Size)\n",
    "Y_pred_3 = model_1.predict_generator(stage_generators2)\n",
    "y_pred_3 = np.argmax(Y_pred_3, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(stage_generators2.classes, y_pred_3))\n",
    "print('Classification Report')\n",
    "target_names = [cls for cls in stage_generators2.class_indices]\n",
    "print(classification_report(stage_generators2.classes, y_pred_3, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
